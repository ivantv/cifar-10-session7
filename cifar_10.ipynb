{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0e8506bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e8506bb",
        "outputId": "6d56798d-2301-4ff3-af5f-b6aefd016dd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "  Using cached torch-2.8.0-cp313-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
            "Collecting torchvision\n",
            "  Using cached torchvision-0.23.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
            "Collecting matplotlib\n",
            "  Using cached matplotlib-3.10.6-cp313-cp313-macosx_11_0_arm64.whl.metadata (11 kB)\n",
            "Collecting tqdm\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting albumentations\n",
            "  Using cached albumentations-2.0.8-py3-none-any.whl.metadata (43 kB)\n",
            "Collecting opencv-python-headless\n",
            "  Using cached opencv_python_headless-4.12.0.88-cp37-abi3-macosx_13_0_arm64.whl.metadata (19 kB)\n",
            "Collecting filelock (from torch)\n",
            "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch)\n",
            "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting setuptools (from torch)\n",
            "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch)\n",
            "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch)\n",
            "  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting numpy (from torchvision)\n",
            "  Using cached numpy-2.3.3-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
            "  Using cached pillow-11.3.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib)\n",
            "  Using cached contourpy-1.3.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Downloading fonttools-4.60.1-cp313-cp313-macosx_10_13_universal2.whl.metadata (112 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
            "  Using cached kiwisolver-1.4.9-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
            "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Collecting scipy>=1.10.0 (from albumentations)\n",
            "  Using cached scipy-1.16.2-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
            "Collecting PyYAML (from albumentations)\n",
            "  Using cached pyyaml-6.0.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
            "Collecting pydantic>=2.9.2 (from albumentations)\n",
            "  Using cached pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
            "Collecting albucore==0.0.24 (from albumentations)\n",
            "  Using cached albucore-0.0.24-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting stringzilla>=3.10.4 (from albucore==0.0.24->albumentations)\n",
            "  Using cached stringzilla-4.1.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (105 kB)\n",
            "Collecting simsimd>=5.9.2 (from albucore==0.0.24->albumentations)\n",
            "  Using cached simsimd-6.5.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (70 kB)\n",
            "Collecting numpy (from torchvision)\n",
            "  Using cached numpy-2.2.6-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic>=2.9.2->albumentations)\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.33.2 (from pydantic>=2.9.2->albumentations)\n",
            "  Using cached pydantic_core-2.33.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic>=2.9.2->albumentations)\n",
            "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
            "  Downloading markupsafe-3.0.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
            "Using cached torch-2.8.0-cp313-none-macosx_11_0_arm64.whl (73.6 MB)\n",
            "Using cached torchvision-0.23.0-cp313-cp313-macosx_11_0_arm64.whl (1.9 MB)\n",
            "Using cached matplotlib-3.10.6-cp313-cp313-macosx_11_0_arm64.whl (8.1 MB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached albumentations-2.0.8-py3-none-any.whl (369 kB)\n",
            "Using cached albucore-0.0.24-py3-none-any.whl (15 kB)\n",
            "Using cached opencv_python_headless-4.12.0.88-cp37-abi3-macosx_13_0_arm64.whl (37.9 MB)\n",
            "Using cached numpy-2.2.6-cp313-cp313-macosx_14_0_arm64.whl (5.1 MB)\n",
            "Using cached contourpy-1.3.3-cp313-cp313-macosx_11_0_arm64.whl (274 kB)\n",
            "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.60.1-cp313-cp313-macosx_10_13_universal2.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached kiwisolver-1.4.9-cp313-cp313-macosx_11_0_arm64.whl (64 kB)\n",
            "Using cached pillow-11.3.0-cp313-cp313-macosx_11_0_arm64.whl (4.7 MB)\n",
            "Using cached pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
            "Using cached pydantic_core-2.33.2-cp313-cp313-macosx_11_0_arm64.whl (1.8 MB)\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
            "Using cached scipy-1.16.2-cp313-cp313-macosx_14_0_arm64.whl (20.9 MB)\n",
            "Using cached simsimd-6.5.3-cp313-cp313-macosx_11_0_arm64.whl (134 kB)\n",
            "Using cached stringzilla-4.1.0-cp313-cp313-macosx_11_0_arm64.whl (126 kB)\n",
            "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
            "Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
            "Using cached fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading markupsafe-3.0.3-cp313-cp313-macosx_11_0_arm64.whl (12 kB)\n",
            "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
            "Using cached pyyaml-6.0.3-cp313-cp313-macosx_11_0_arm64.whl (173 kB)\n",
            "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "Installing collected packages: simsimd, mpmath, typing-extensions, tqdm, sympy, stringzilla, setuptools, PyYAML, pyparsing, pillow, numpy, networkx, MarkupSafe, kiwisolver, fsspec, fonttools, filelock, cycler, annotated-types, typing-inspection, scipy, pydantic-core, opencv-python-headless, jinja2, contourpy, torch, pydantic, matplotlib, albucore, torchvision, albumentations\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31/31\u001b[0m [albumentations]m [albumentations]eadless]\n",
            "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.3 PyYAML-6.0.3 albucore-0.0.24 albumentations-2.0.8 annotated-types-0.7.0 contourpy-1.3.3 cycler-0.12.1 filelock-3.19.1 fonttools-4.60.1 fsspec-2025.9.0 jinja2-3.1.6 kiwisolver-1.4.9 matplotlib-3.10.6 mpmath-1.3.0 networkx-3.5 numpy-2.2.6 opencv-python-headless-4.12.0.88 pillow-11.3.0 pydantic-2.11.9 pydantic-core-2.33.2 pyparsing-3.2.5 scipy-1.16.2 setuptools-80.9.0 simsimd-6.5.3 stringzilla-4.1.0 sympy-1.14.0 torch-2.8.0 torchvision-0.23.0 tqdm-4.67.1 typing-extensions-4.15.0 typing-inspection-0.4.2\n"
          ]
        }
      ],
      "source": [
        "! python3 -m pip install torch torchvision matplotlib tqdm albumentations opencv-python-headless\n",
        "from __future__ import annotations\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d05da548",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d05da548",
        "outputId": "e9f2655c-c0f0-49a4-dcab-7ab4ee8d46bf"
      },
      "outputs": [],
      "source": [
        "# Load CIFAR-10 with basic transforms\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_tfms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_ds = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_tfms)\n",
        "test_ds = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_tfms)\n",
        "\n",
        "classes = train_ds.classes\n",
        "print('Classes:', classes)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=256, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_ds, batch_size=256, shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fde55d81",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fde55d81",
        "outputId": "85ab3495-1cd9-41df-b723-3b353933f268"
      },
      "outputs": [],
      "source": [
        "# Compute dataset mean/std per channel (RGB) on training set\n",
        "sum_ = torch.zeros(3)\n",
        "sum_sq = torch.zeros(3)\n",
        "count = 0\n",
        "for imgs, _ in DataLoader(train_ds, batch_size=512, shuffle=False, num_workers=2):\n",
        "    b, c, h, w = imgs.shape\n",
        "    imgs = imgs.view(b, c, -1)\n",
        "    sum_ += imgs.mean(dim=(0, 2)) * b\n",
        "    sum_sq += (imgs ** 2).mean(dim=(0, 2)) * b\n",
        "    count += b\n",
        "\n",
        "mean = (sum_ / count).tolist()\n",
        "std = ((sum_sq / count - torch.tensor(mean) ** 2).sqrt()).tolist()\n",
        "print('Train mean:', mean)\n",
        "print('Train std:', std)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bc857a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bc857a6",
        "outputId": "f30e2c4d-8fcc-4bd0-8c78-b9c2fc131cde"
      },
      "outputs": [],
      "source": [
        "# Class distribution in training set\n",
        "counts = Counter(train_ds.targets)\n",
        "print({classes[k]: counts[k] for k in range(len(classes))})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9415bfb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "e9415bfb",
        "outputId": "b486047e-93e8-41a4-d4cf-02b761fac178"
      },
      "outputs": [],
      "source": [
        "# Visualize a grid of training images\n",
        "batch = next(iter(train_loader))\n",
        "imgs, labels = batch\n",
        "fig, axes = plt.subplots(4, 8, figsize=(12, 6))\n",
        "for ax, img, lbl in zip(axes.flatten(), imgs[:32], labels[:32]):\n",
        "    ax.imshow(np.transpose(img.numpy(), (1, 2, 0)))\n",
        "    ax.set_title(classes[lbl])\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ad70f1e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "2ad70f1e",
        "outputId": "089fd564-3f97-4962-cb49-46fc20dd3213"
      },
      "outputs": [],
      "source": [
        "# Preview common augmentations\n",
        "aug_tfms = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "aug_ds = datasets.CIFAR10(root='./data', train=True, download=False, transform=aug_tfms)\n",
        "aug_loader = DataLoader(aug_ds, batch_size=32, shuffle=True)\n",
        "\n",
        "aug_imgs, aug_labels = next(iter(aug_loader))\n",
        "# de-normalize for display\n",
        "aug_imgs_disp = aug_imgs.clone()\n",
        "for c in range(3):\n",
        "    aug_imgs_disp[:, c] = aug_imgs_disp[:, c] * std[c] + mean[c]\n",
        "\n",
        "fig, axes = plt.subplots(4, 8, figsize=(12, 6))\n",
        "for ax, img, lbl in zip(axes.flatten(), aug_imgs_disp[:32], aug_labels[:32]):\n",
        "    ax.imshow(np.transpose(img.numpy(), (1, 2, 0)))\n",
        "    ax.set_title(classes[lbl])\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ebe26e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ebe26e4",
        "outputId": "8337000a-3a74-4d7e-f658-d36bcd60400c"
      },
      "outputs": [],
      "source": [
        "# Albumentations transforms using dataset mean\n",
        "mean, std\n",
        "alb_train_tfms = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
        "    A.CoarseDropout(\n",
        "        max_holes=1,\n",
        "        max_height=16,\n",
        "        max_width=16,\n",
        "        min_holes=1,\n",
        "        min_height=16,\n",
        "        min_width=16,\n",
        "        fill_value=(int(mean[0]*255), int(mean[1]*255), int(mean[2]*255)),\n",
        "        mask_fill_value=None,\n",
        "        p=0.5,\n",
        "    ),\n",
        "    A.Normalize(mean=mean, std=std),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "alb_test_tfms = A.Compose([\n",
        "    A.Normalize(mean=mean, std=std),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "# Wrapper to apply Albumentations on torchvision dataset\n",
        "class AlbumentationsCIFAR(torchvision.datasets.CIFAR10):\n",
        "    def __init__(self, *args, transform=None, **kwargs):\n",
        "        super().__init__(*args, transform=None, **kwargs)\n",
        "        self.alb_transform = transform\n",
        "    def __getitem__(self, idx):\n",
        "        img, target = self.data[idx], self.targets[idx]  # HWC RGB uint8\n",
        "        if self.alb_transform is not None:\n",
        "            augmented = self.alb_transform(image=img)\n",
        "            img = augmented['image']\n",
        "        return img, target\n",
        "\n",
        "train_ds_alb = AlbumentationsCIFAR(root='./data', train=True, download=False, transform=alb_train_tfms)\n",
        "test_ds_alb = AlbumentationsCIFAR(root='./data', train=False, download=False, transform=alb_test_tfms)\n",
        "\n",
        "train_loader = DataLoader(train_ds_alb, batch_size=128, shuffle=True, num_workers=0)\n",
        "test_loader = DataLoader(test_ds_alb, batch_size=128, shuffle=False, num_workers=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0e60b17",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0e60b17",
        "outputId": "2b1f9ac6-06c4-47f9-fe5d-050485fb2248"
      },
      "outputs": [],
      "source": [
        "# C1-C2-C3-C4 CNN with last stride 2, then GAP and classifier\n",
        "from model import Net\n",
        "import torch\n",
        "\n",
        "model = Net().to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "print(sum(p.numel() for p in model.parameters()))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "585b63d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "585b63d5",
        "outputId": "f8033020-8723-4c75-c33b-915fd3e1d8a2"
      },
      "outputs": [],
      "source": [
        "! pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6787435",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6787435",
        "outputId": "fbaa4dcf-2749-4332-c68c-7e93ee2bf971"
      },
      "outputs": [],
      "source": [
        "# Receptive field quick check\n",
        "# Stack: C1(3x3,3x3), C2(3x3,3x3), C3(3x3,3x3), C4(3x3, 3x3 s=2), then 7x7, 5x5, 5x5\n",
        "layers = [\n",
        "    (3,1), (3,1),  # C1\n",
        "    (3,1), (3,1),  # C2\n",
        "    (3,1), (3,1),  # C3\n",
        "    (3,1), (3,2),  # C4 start (downsample)\n",
        "    (7,1), (5,1), (5,1),  # extra large kernels in C4\n",
        "]\n",
        "rf = 1\n",
        "jump = 1\n",
        "for k,s in layers:\n",
        "    rf = rf + (k-1)*jump\n",
        "    jump *= s\n",
        "print('Approx RF:', rf)  # expect >= 45\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p2eh21V4FzP7",
      "metadata": {
        "id": "p2eh21V4FzP7"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes.\n",
        "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = F.nll_loss(y_pred, target)\n",
        "    train_losses.append(loss)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update pbar-tqdm\n",
        "\n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "\n",
        "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "    train_acc.append(100*correct/processed)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    test_acc.append(100. * correct / len(test_loader.dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DjBaRKwuF0yn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjBaRKwuF0yn",
        "outputId": "a292d72d-1bfa-40f9-e62b-04a82216209f"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "model =  Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "EPOCHS = 20\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72281e22",
      "metadata": {
        "id": "72281e22"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
